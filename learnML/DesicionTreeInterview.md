[toc]

# Job 决策树 面试题整理

## 1. 什么是决策树？

从三个角度来理解。

1. 一棵树
2. if-else规则的集合。从根结点到叶结点的路径实际上决定了一个集合
3. 定义在特征空间与类空间上的条件概率分布，决策树实际上是将特征空间划分成了互不相交的单元，每个从根到叶的路径对应着一个单元。决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。实际中，哪个类别有较高的条件概率，就把该单元中的实例强行划分为该类别。

因此，对于一棵分类决策树可以表示为

$$y = \sum_{D_i \subset D} c_i I(x \in D_i)$$

其中， $\{D_i\}$ 是集合 D 的一个分割。$D_i$ 就是由根结点到叶结点上的 if-else 规则决定的集合。$c_i$ 是在这个集合上的取值。


## 2. 决策树与其它模型相比的优点

1. 可解释性
2. 计算速度快

## 3. 如何学习一棵决策树

有三个部分：1. 特征选择 2. 树的生成 3. 剪枝

### 选择特征时的指标

有四个

1. 信息增益，对于 ID3
2. 信息增益比，对应 C4.5
3. Gini系数，对应CART分类树
4. 方差 对应 CART 回归树

终止的条件： 
1. 所有的样本都属于一个类。
2. 没有可用于分类的特征。（因为ID3和C4.5中每个特征只能使用一次）
3. 指标的变化小于阈值。如分裂之后信息增益的变化小于阈值。

## 剪枝

分为预剪枝和后剪枝。

### 预剪枝

预剪枝是在生成树的时候进行的。在一个结点处进行分裂时判断分裂此结点是否会带来泛化性能的提升。如果不能，就不进行分裂，相当于剪枝。反之，，就进行分裂。

预剪枝的优点：
1. 有效缓解过拟合
2. 减少时间和空间开销。因为许多结点根本就不会被分裂展开。

缺点：
会增加欠拟合的风险。可能会出现某个结点处的分裂虽然不会导致泛化性的增加，但是在这个结点分裂之后的子结点进行分裂后可能会带来泛化性的巨大提升，预剪枝会直接排除掉这种可能。

### 后剪枝

后剪枝是在生成树后的时候进行的。在建立树之后，自底向上，判断每一个非叶结点是否能导致泛化性的增加，如果能，就保留；如果不能，就剪枝。

后剪枝的优点：
1. 后剪枝考虑的模型的空间更大，因此相比五预剪枝，其欠拟合的风险更小，并且缓解过拟合的效果也更好。

后剪枝的缺点：
1. 运算的时间的空间开销大于预剪枝和不剪枝。因为需要在树生成之后判断所有的结点的。

### 如何判断泛化性能是否上升

预剪枝和后剪枝都需要判断泛化性能是否增加，到底应该如何判断泛化性能是否提升？在实际应用中，一般都是利用测试集上的acc 来判断表达泛化性的。因此需要比较分裂后**测试集**上的acc和分裂后在**测试集**上的acc比不分裂大，则说明分裂会导致泛化性能的提升，因此就应该在这个地方分裂。否则，就不应该在这个地方分裂。

## 为什么用信息增益比？

因为信息增益对于可取值数目较多的属性有所偏好。

### 决策树几种常用的算法以及如何选择划分的特征

常用的几种决策树算法有ID3、C4.5、CART等；

1. ID3使用的是信息熵增益选大的方法划分数据，
2. C4.5是使用增益率选大的方法划分数据，
3. CART使用的是基尼指数选小的划分方法

# References

1. [数据挖掘面试题之决策树必知必会 - 简书](https://www.jianshu.com/p/fb97b21aeb1d)
